# For this project we will be exploring publicly available data from [LendingClub.com](www.lendingclub.com).
# Lending Club connects people who need money (borrowers) with people who have money (investors).
# Hopefully, as an investor you would want to invest in people who showed a profile of
# having a high probability of paying you back.
# We will try to create a model that will help predict this.

# Here are what the columns represent:
# * credit.policy: 1 if the customer meets the credit underwriting criteria of LendingClub.com, and 0 otherwise.
# * purpose: The purpose of the loan (takes values "credit_card", "debt_consolidation", "educational", "major_purchase", "small_business", and "all_other").
# * int.rate: The interest rate of the loan, as a proportion (a rate of 11% would be stored as 0.11). Borrowers judged by LendingClub.com to be more risky are assigned higher interest rates.
# * installment: The monthly installments owed by the borrower if the loan is funded.
# * log.annual.inc: The natural log of the self-reported annual income of the borrower.
# * dti: The debt-to-income ratio of the borrower (amount of debt divided by annual income).
# * fico: The FICO credit score of the borrower.
# * days.with.cr.line: The number of days the borrower has had a credit line.
# * revol.bal: The borrower's revolving balance (amount unpaid at the end of the credit card billing cycle).
# * revol.util: The borrower's revolving line utilization rate (the amount of the credit line used relative to total credit available).
# * inq.last.6mths: The borrower's number of inquiries by creditors in the last 6 months.
# * delinq.2yrs: The number of times the borrower had been 30+ days past due on a payment in the past 2 years.
# * pub.rec: The borrower's number of derogatory public records (bankruptcy filings, tax liens, or judgments).

# Import the usual libraries for pandas and plotting. You can import sklearn later on.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Utils to see all dataframe columns
desired_width = 320
pd.set_option('display.width', desired_width)
pd.set_option('display.max_columns', 100)


def separator():
    print('-' * 20)


# Use pandas to read loan_data.csv as a dataframe called loans.
# Check out the info(), head(), and describe() methods on loans.

loans = pd.read_csv('loan_data.csv')

print(loans.head())

#    credit.policy             purpose  int.rate  installment  log.annual.inc    dti  fico  days.with.cr.line  revol.bal  revol.util  inq.last.6mths  delinq.2yrs  pub.rec  not.fully.paid
# 0              1  debt_consolidation    0.1189       829.10       11.350407  19.48   737        5639.958333      28854        52.1               0            0        0               0
# 1              1         credit_card    0.1071       228.22       11.082143  14.29   707        2760.000000      33623        76.7               0            0        0               0
# 2              1  debt_consolidation    0.1357       366.86       10.373491  11.63   682        4710.000000       3511        25.6               1            0        0               0
# 3              1  debt_consolidation    0.1008       162.34       11.350407   8.10   712        2699.958333      33667        73.2               1            0        0               0
# 4              1         credit_card    0.1426       102.92       11.299732  14.97   667        4066.000000       4740        39.5               0            1        0               0
separator()

print(loans.info())

# <class 'pandas.core.frame.DataFrame'>
# RangeIndex: 9578 entries, 0 to 9577
# Data columns (total 14 columns):
# credit.policy        9578 non-null int64
# purpose              9578 non-null object
# int.rate             9578 non-null float64
# installment          9578 non-null float64
# log.annual.inc       9578 non-null float64
# dti                  9578 non-null float64
# fico                 9578 non-null int64
# days.with.cr.line    9578 non-null float64
# revol.bal            9578 non-null int64
# revol.util           9578 non-null float64
# inq.last.6mths       9578 non-null int64
# delinq.2yrs          9578 non-null int64
# pub.rec              9578 non-null int64
# not.fully.paid       9578 non-null int64
# dtypes: float64(6), int64(7), object(1)
# memory usage: 1.0+ MB
# None
separator()

print(loans.describe())

#        credit.policy     int.rate  installment  log.annual.inc          dti         fico  days.with.cr.line     revol.bal   revol.util  inq.last.6mths  delinq.2yrs      pub.rec  not.fully.paid
# count    9578.000000  9578.000000  9578.000000     9578.000000  9578.000000  9578.000000        9578.000000  9.578000e+03  9578.000000     9578.000000  9578.000000  9578.000000     9578.000000
# mean        0.804970     0.122640   319.089413       10.932117    12.606679   710.846314        4560.767197  1.691396e+04    46.799236        1.577469     0.163708     0.062122        0.160054
# std         0.396245     0.026847   207.071301        0.614813     6.883970    37.970537        2496.930377  3.375619e+04    29.014417        2.200245     0.546215     0.262126        0.366676
# min         0.000000     0.060000    15.670000        7.547502     0.000000   612.000000         178.958333  0.000000e+00     0.000000        0.000000     0.000000     0.000000        0.000000
# 25%         1.000000     0.103900   163.770000       10.558414     7.212500   682.000000        2820.000000  3.187000e+03    22.600000        0.000000     0.000000     0.000000        0.000000
# 50%         1.000000     0.122100   268.950000       10.928884    12.665000   707.000000        4139.958333  8.596000e+03    46.300000        1.000000     0.000000     0.000000        0.000000
# 75%         1.000000     0.140700   432.762500       11.291293    17.950000   737.000000        5730.000000  1.824950e+04    70.900000        2.000000     0.000000     0.000000        0.000000
# max         1.000000     0.216400   940.140000       14.528354    29.960000   827.000000       17639.958330  1.207359e+06   119.000000       33.000000    13.000000     5.000000        1.000000
separator()

# Exploratory Data Analysis
# Create a histogram of two FICO distributions on top of each other, one for each credit.policy outcome.

loans[loans['credit.policy'] == 1]['fico'].hist(alpha=0.5, color='blue', bins=30, label='Credit.Policy=1')
loans[loans['credit.policy'] == 0]['fico'].hist(alpha=0.5, color='red', bins=30, label='Credit.Policy=0')
plt.legend()
plt.xlabel('FICO')
plt.show()

# Create a similar figure, except this time select by the not.fully.paid column

loans[loans['not.fully.paid'] == 1]['fico'].hist(alpha=0.5, color='blue', bins=30, label='not.fully.paid=1')
loans[loans['not.fully.paid'] == 0]['fico'].hist(alpha=0.5, color='red', bins=30, label='not.fully.paid=0')
plt.legend()
plt.xlabel('FICO')
plt.show()

# Create a countplot using seaborn showing the counts of loans by purpose, with the color hue defined by not.fully.paid.

plt.figure(figsize=(12, 4))
sns.countplot(x='purpose', hue='not.fully.paid', data=loans)
plt.show()

# Let's see the trend between FICO score and interest rate. Recreate the following jointplot.

sns.jointplot(x='fico', y='int.rate', data=loans, color='purple')
plt.show()

# Create the following lmplots to see if the trend differed between not.fully.paid and credit.policy.
# Check the documentation for lmplot() if you can't figure out how to separate it into columns.

plt.figure(figsize=(12, 4))
sns.lmplot(y='int.rate', x='fico', data=loans, hue='credit.policy',
           col='not.fully.paid')
plt.show()

# Setting up the data

# <class 'pandas.core.frame.DataFrame'>
# RangeIndex: 9578 entries, 0 to 9577
# Data columns (total 14 columns):
# credit.policy        9578 non-null int64
# purpose              9578 non-null object
# int.rate             9578 non-null float64
# installment          9578 non-null float64
# log.annual.inc       9578 non-null float64
# dti                  9578 non-null float64
# fico                 9578 non-null int64
# days.with.cr.line    9578 non-null float64
# revol.bal            9578 non-null int64
# revol.util           9578 non-null float64
# inq.last.6mths       9578 non-null int64
# delinq.2yrs          9578 non-null int64
# pub.rec              9578 non-null int64
# not.fully.paid       9578 non-null int64
# dtypes: float64(6), int64(7), object(1)
# memory usage: 1.0+ MB
# None


## Categorical Features

# Notice that the **purpose** column as categorical
# That means we need to transform them using dummy variables so sklearn will be able to understand them.
# Let's do this in one clean step using pd.get_dummies.
# Let's show you a way of dealing with these columns that can be expanded to multiple categorical features if necessary.

# Create a list of 1 element containing the string 'purpose'. Call this list cat_feats.

cat_feats = ['purpose']

# Now use pd.get_dummies(loans,columns=cat_feats,drop_first=True) to create a fixed larger dataframe
# that has new feature columns with dummy variables. Set this dataframe as final_data.

final_data = pd.get_dummies(loans, columns=cat_feats, drop_first=True)

print(final_data.info())

# <class 'pandas.core.frame.DataFrame'>
# RangeIndex: 9578 entries, 0 to 9577
# Data columns (total 19 columns):
# credit.policy                 9578 non-null int64
# int.rate                      9578 non-null float64
# installment                   9578 non-null float64
# log.annual.inc                9578 non-null float64
# dti                           9578 non-null float64
# fico                          9578 non-null int64
# days.with.cr.line             9578 non-null float64
# revol.bal                     9578 non-null int64
# revol.util                    9578 non-null float64
# inq.last.6mths                9578 non-null int64
# delinq.2yrs                   9578 non-null int64
# pub.rec                       9578 non-null int64
# not.fully.paid                9578 non-null int64
# purpose_credit_card           9578 non-null uint8
# purpose_debt_consolidation    9578 non-null uint8
# purpose_educational           9578 non-null uint8
# purpose_home_improvement      9578 non-null uint8
# purpose_major_purchase        9578 non-null uint8
# purpose_small_business        9578 non-null uint8
# dtypes: float64(6), int64(7), uint8(6)
# memory usage: 1.0 MB
# None


## Train Test Split
# Now its time to split our data into a training set and a testing set!
# Use sklearn to split your data into a training set and a testing set as we've done in the past.

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(final_data.drop('not.fully.paid', axis=1),
                                                    final_data['not.fully.paid'], test_size=0.3, random_state=101)

## Training a Decision Tree Model
# Let's start by training a single decision tree first!
# Import DecisionTreeClassifier
# Create an instance of DecisionTreeClassifier() called dtree and fit it to the training data.

from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier()
model.fit(X_train, y_train)

# Predictions and Evaluation of Decision Tree
# Create predictions from the test set and create a classification report and a confusion matrix.

predictions = model.predict(X_test)

from sklearn.metrics import classification_report, confusion_matrix

print(classification_report(y_test, predictions))
#               precision    recall  f1-score   support
#
#            0       0.85      0.83      0.84      2431
#            1       0.19      0.22      0.20       443
#
#     accuracy                           0.73      2874
#    macro avg       0.52      0.52      0.52      2874
# weighted avg       0.75      0.73      0.74      2874


print(confusion_matrix(y_test, predictions))

# [[2006  425]
#  [ 346   97]]
