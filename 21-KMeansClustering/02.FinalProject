# K Means Clustering Project
# For this project we will attempt to use KMeans Clustering to cluster Universities
# into to two groups, Private and Public.

# It is very important to note, we actually have the labels for this data set,
# but we will NOT use them for the KMeans clustering algorithm,
# since that is an unsupervised learning algorithm.

# When using the Kmeans algorithm under normal circumstances, it is because you don't have labels.
# In this case we will use the labels to try to get an idea of how well the algorithm performed,
# but you won't usually do this for Kmeans, so the classification report
# and confusion matrix at the end of this project, don't truly make sense in a real world setting!.

## The Data

# We will use a data frame with 777 observations on the following 18 variables.
# * Private A factor with levels No and Yes indicating private or public university
# * Apps Number of applications received
# * Accept Number of applications accepted
# * Enroll Number of new students enrolled
# * Top10perc Pct. new students from top 10% of H.S. class
# * Top25perc Pct. new students from top 25% of H.S. class
# * F.Undergrad Number of fulltime undergraduates
# * P.Undergrad Number of parttime undergraduates
# * Outstate Out-of-state tuition
# * Room.Board Room and board costs
# * Books Estimated book costs
# * Personal Estimated personal spending
# * PhD Pct. of faculty with Ph.D.â€™s
# * Terminal Pct. of faculty with terminal degree
# * S.F.Ratio Student/faculty ratio
# * perc.alumni Pct. alumni who donate
# * Expend Instructional expenditure per student
# * Grad.Rate Graduation rate

# Import the libraries you usually use for data analysis.

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Read in the College_Data file using read_csv. Figure out how to set the first column as the index

data = pd.read_csv('College_Data')

print(data.head())

#                      Unnamed: 0 Private  Apps  ...  perc.alumni  Expend  Grad.Rate
# 0  Abilene Christian University     Yes  1660  ...           12    7041         60
# 1            Adelphi University     Yes  2186  ...           16   10527         56
# 2                Adrian College     Yes  1428  ...           30    8735         54
# 3           Agnes Scott College     Yes   417  ...           37   19016         59
# 4     Alaska Pacific University     Yes   193  ...            2   10922         15

print(data.info())

# <class 'pandas.core.frame.DataFrame'>
# RangeIndex: 777 entries, 0 to 776
# Data columns (total 19 columns):
# Unnamed: 0     777 non-null object
# Private        777 non-null object
# Apps           777 non-null int64
# Accept         777 non-null int64
# Enroll         777 non-null int64
# Top10perc      777 non-null int64
# Top25perc      777 non-null int64
# F.Undergrad    777 non-null int64
# P.Undergrad    777 non-null int64
# Outstate       777 non-null int64
# Room.Board     777 non-null int64
# Books          777 non-null int64
# Personal       777 non-null int64
# PhD            777 non-null int64
# Terminal       777 non-null int64
# S.F.Ratio      777 non-null float64
# perc.alumni    777 non-null int64
# Expend         777 non-null int64
# Grad.Rate      777 non-null int64
# dtypes: float64(1), int64(16), object(2)
# memory usage: 115.5+ KB
# None

print(data.describe())

#                Apps        Accept  ...        Expend  Grad.Rate
# count    777.000000    777.000000  ...    777.000000  777.00000
# mean    3001.638353   2018.804376  ...   9660.171171   65.46332
# std     3870.201484   2451.113971  ...   5221.768440   17.17771
# min       81.000000     72.000000  ...   3186.000000   10.00000
# 25%      776.000000    604.000000  ...   6751.000000   53.00000
# 50%     1558.000000   1110.000000  ...   8377.000000   65.00000
# 75%     3624.000000   2424.000000  ...  10830.000000   78.00000
# max    48094.000000  26330.000000  ...  56233.000000  118.00000


# Create a scatterplot of Grad.Rate versus Room.Board where the points are colored by the Private column.

sns.scatterplot(x='Room.Board', y='Grad.Rate', data=data, hue='Private')
plt.show()

# Create a scatterplot of F.Undergrad versus Outstate where the points are colored by the Private column

sns.scatterplot(x='Outstate', y='F.Undergrad', data=data, hue='Private')
plt.show()

# Create a stacked histogram showing Out of State Tuition based on the Private column.
# Try doing this using [sns.FacetGrid](https://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.FacetGrid.html).
# If that is too tricky, see if you can do it just by using two instances of pandas.plot(kind='hist').

sns.set_style('darkgrid')
g = sns.FacetGrid(data, hue="Private", palette='coolwarm', size=6, aspect=2)
g = g.map(plt.hist, 'Outstate', bins=20, alpha=0.7)
plt.show()

# Create a similar histogram for the Grad.Rate column.

sns.set_style('darkgrid')
g = sns.FacetGrid(data, hue="Private", palette='coolwarm', size=6, aspect=2)
g = g.map(plt.hist, 'Grad.Rate', bins=20, alpha=0.7)
plt.show()

# Notice how there seems to be a private school with a graduation rate of higher than 100%.
# What is the name of that school?

print(data[data['Grad.Rate'] > 100])

#            Unnamed: 0 Private  Apps  ...  perc.alumni  Expend  Grad.Rate
# 95  Cazenovia College     Yes  3847  ...           20    7697        118

# Set that school's graduation rate to 100 so it makes sense.
# You may get a warning not an error) when doing this operation, so use dataframe operations or just re-do
# the histogram visualization to make sure it actually went through.

data['Grad.Rate']['Cazenovia College'] = 100
print(data[data['Grad.Rate'] > 100])

## K Means Cluster Creation
# Now it is time to create the Cluster labels!

# Import KMeans from SciKit Learn
from sklearn.cluster import KMeans

# Create an instance of a K Means model with 2 clusters
kmeans = KMeans(n_clusters=2)

# Fit the model to all the data except for the Private label
df = data.drop('Private', axis=1)
kmeans.fit(df.drop('Unnamed: 0', axis=1))

# What are the cluster center vectors?
print(kmeans.cluster_centers_)


# [1 rows x 19 columns]
# [[1.03631389e+04 6.55089815e+03 2.56972222e+03 4.14907407e+01
#   7.02037037e+01 1.30619352e+04 2.46486111e+03 1.07191759e+04
#   4.64347222e+03 5.95212963e+02 1.71420370e+03 8.63981481e+01
#   9.13333333e+01 1.40277778e+01 2.00740741e+01 1.41705000e+04
#   6.75925926e+01]
#  [1.81323468e+03 1.28716592e+03 4.91044843e+02 2.53094170e+01
#   5.34708520e+01 2.18854858e+03 5.95458894e+02 1.03957085e+04
#   4.31136472e+03 5.41982063e+02 1.28033632e+03 7.04424514e+01
#   7.78251121e+01 1.40997010e+01 2.31748879e+01 8.93204634e+03
#   6.51195815e+01]]

# Evaluation
# There is no perfect way to evaluate clustering if you don't have the labels,
# however since this is just an exercise, we do have the labels, so we take advantage
# of this to evaluate our clusters, keep in mind, you usually won't have this luxury in the real world.

# Create a new column for df called 'Cluster', which is a 1 for a Private school, and a 0 for a public school

def converter(cluster):
    if cluster == 'Yes':
        return 1
    else:
        return 0


data['Cluster'] = data['Private'].apply(converter)

print(data.head())

#                      Unnamed: 0 Private  Apps  ...  Expend  Grad.Rate  Cluster
# 0  Abilene Christian University     Yes  1660  ...    7041         60        1
# 1            Adelphi University     Yes  2186  ...   10527         56        1
# 2                Adrian College     Yes  1428  ...    8735         54        1
# 3           Agnes Scott College     Yes   417  ...   19016         59        1
# 4     Alaska Pacific University     Yes   193  ...   10922         15        1

# Create a confusion matrix and classification report to see how well the Kmeans
# clustering worked without being given any labels.

from sklearn.metrics import confusion_matrix, classification_report

print(confusion_matrix(data['Cluster'], kmeans.labels_))

# [[138  74]
#  [531  34]]

print(classification_report(data['Cluster'], kmeans.labels_))

#               precision    recall  f1-score   support
#
#            0       0.21      0.65      0.31       212
#            1       0.31      0.06      0.10       565
#
#     accuracy                           0.22       777
#    macro avg       0.26      0.36      0.21       777
# weighted avg       0.29      0.22      0.16       777
