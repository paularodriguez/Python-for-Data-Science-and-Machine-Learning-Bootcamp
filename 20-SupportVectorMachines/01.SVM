import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


def separator():
    print('-' * 20)


# dataset from sklearn

from sklearn.datasets import load_breast_cancer

cancer = load_breast_cancer()

print(cancer.keys())
# dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])
separator()

df_feat = pd.DataFrame(cancer['data'], columns=cancer['feature_names'])

print(df_feat.head())
#    mean radius  mean texture  ...  worst symmetry  worst fractal dimension
# 0        17.99         10.38  ...          0.4601                  0.11890
# 1        20.57         17.77  ...          0.2750                  0.08902
# 2        19.69         21.25  ...          0.3613                  0.08758
# 3        11.42         20.38  ...          0.6638                  0.17300
# 4        20.29         14.34  ...          0.2364                  0.07678
separator()

print(df_feat.info())
# <class 'pandas.core.frame.DataFrame'>
# RangeIndex: 569 entries, 0 to 568
# Data columns (total 30 columns):
# mean radius                569 non-null float64
# mean texture               569 non-null float64
# mean perimeter             569 non-null float64
# mean area                  569 non-null float64
# mean smoothness            569 non-null float64
# mean compactness           569 non-null float64
# mean concavity             569 non-null float64
# mean concave points        569 non-null float64
# mean symmetry              569 non-null float64
# mean fractal dimension     569 non-null float64
# radius error               569 non-null float64
# texture error              569 non-null float64
# perimeter error            569 non-null float64
# area error                 569 non-null float64
# smoothness error           569 non-null float64
# compactness error          569 non-null float64
# concavity error            569 non-null float64
# concave points error       569 non-null float64
# symmetry error             569 non-null float64
# fractal dimension error    569 non-null float64
# worst radius               569 non-null float64
# worst texture              569 non-null float64
# worst perimeter            569 non-null float64
# worst area                 569 non-null float64
# worst smoothness           569 non-null float64
# worst compactness          569 non-null float64
# worst concavity            569 non-null float64
# worst concave points       569 non-null float64
# worst symmetry             569 non-null float64
# worst fractal dimension    569 non-null float64
# dtypes: float64(30)
# memory usage: 133.5 KB
# None
separator()

print(cancer['target_names'])
# ['malignant' 'benign']
separator()

# Split data
from sklearn.model_selection import train_test_split

X = df_feat
df_target = pd.DataFrame(cancer['target'], columns=['Cancer'])

X_train, X_test, y_train, y_test = train_test_split(df_feat, np.ravel(df_target), test_size=0.30, random_state=101)
# Train model

from sklearn.svm import SVC

model = SVC()

print(model)
# SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
#     decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',
#     max_iter=-1, probability=False, random_state=None, shrinking=True,
#     tol=0.001, verbose=False)
separator()

model.fit(X_train, y_train)

# Prediction

predictions = model.predict(X_test)

# Evaluation

from sklearn.metrics import classification_report, confusion_matrix

print(classification_report(y_test, predictions))

#               precision    recall  f1-score   support
#
#            0       0.95      0.85      0.90        66
#            1       0.91      0.97      0.94       105
#
#     accuracy                           0.92       171
#    macro avg       0.93      0.91      0.92       171
# weighted avg       0.93      0.92      0.92       171

print(confusion_matrix(y_test, predictions))

# [[ 56  10]
#  [  3 102]]


# Improve results by adjusting model parameters

from sklearn.model_selection import GridSearchCV

# SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
#     decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',
#     max_iter=-1, probability=False, random_state=None, shrinking=True,
#     tol=0.001, verbose=False)

param_grid = {
    'C': [0.1, 1, 10, 100, 1000],
    'gamma': [1, 0.1, 0.01, 0.001, 0.0001]
}

grid = GridSearchCV(SVC(), param_grid, verbose=3)
grid.fit(X_train, y_train)

# It runs a foor loop to find the best parameter combination

# [Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    1.1s finished

# To see best values:
print(grid.best_params_)

# {'C': 1, 'gamma': 0.0001}

print(grid.best_estimator_)
# SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
#     decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',
#     max_iter=-1, probability=False, random_state=None, shrinking=True,
#     tol=0.001, verbose=False)

print(grid.best_score_)
# 0.9472468354430379

# Now, we are going to redo the model using the obtained parameters

grid_predictions = grid.predict(X_test)

print(classification_report(y_test, grid_predictions))

#               precision    recall  f1-score   support
#
#            0       0.94      0.89      0.91        66
#            1       0.94      0.96      0.95       105
#
#     accuracy                           0.94       171
#    macro avg       0.94      0.93      0.93       171
# weighted avg       0.94      0.94      0.94       171

print(confusion_matrix(y_test, grid_predictions))

# [[ 59   7]
#  [  4 101]]